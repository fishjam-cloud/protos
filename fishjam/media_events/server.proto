syntax = "proto3";

package media_events.server;

import "fishjam/media_events/shared.proto";

// Defines any type of media event message sent between Fishjam and a peer
message MediaEvent {
  message SimulcastConfig {
    bool enabled = 1;
    repeated media_events.shared.Encoding active_encodings = 2;
    repeated media_events.shared.Encoding disabled_encodings = 3;
  }

  message Track {
    string track_id = 1;
    media_events.shared.Metadata metadata = 2;
    string simulcast_config = 3;
  }

  // WebRTC Endpoint -> Peer

  // Contains information about updated metadata of one of the endpoints
  message EndpointUpdated {
    string endpoint_id = 1;
    media_events.shared.Metadata metadata = 2;
  }

  // Contains information about new metadata of one of tracks
  message TrackUpdated {
    string endpoint_id = 1;
    string track_id = 2;
    media_events.shared.Metadata metadata = 3;
  }

  //  Informs that one of the peers has added one or more tracks.
  //  It contains:
  //  - an id of endpoint associated with that peer,
  //  - a map of all tracks with `track_id`'s as keys and objects with `track_metadata` and simulcast conifg as a value
  message TracksAdded {
    string endpoint_id = 1;
    repeated Track tracks = 2;
  }

  // Contains a list of tracks which have been removed by some peer and id of that peer's
  message TracksRemoved {
    string endpoint_id = 1;
    repeated string track_ids = 2;
  }

  // Message sent to all peers in the room after a new endpoint was added.
  // It contains id and metadata of the new endpoint.
  message EndpointAdded {
    string endpoint_id = 1;
    media_events.shared.Metadata metadata = 2;
  }

  // Message sent to the peer after connecting to the WebRTC Endpoint.
  // It contains the id of that peer's endpoint and a list of information about endpoints in the Engine
  // (id, metadata, a `trackIdToMetadata` and tracks like seen in `tracksAdded`)
  // TODO: SIMULCAST
  message Connected {
    message Endpoint {
      string endpoint_id = 1;
      string endpoint_type = 2;
      media_events.shared.Metadata metadata = 3;
      repeated Track tracks = 4;
    }

    string endpoint_id = 1;
    repeated Endpoint endpoints = 2;
  }

  // Sent to all remaining peers in the room after some endpoint was removed. It contains an id of the removed endpoint.
  message EndpointRemoved {
    string endpoint_id = 1;
  }

  // Informs that an error occurred on the server providing a message to show
  message Error {
    string message = 1;
  }

  // WebRTC Enpoint -> Peer

  // Contains information about the number  of audio and video tracks that will be sent from the engine
  // to the peer and information regarding the integrated TURN server.
  message OfferData {
    message TrackTypes {
      int32 audio = 1;
      int32 video = 2;
    }

    TrackTypes tracks_types = 1;
  }

  // Contains an SDP answer and mapping between `mid` and `track_id` for all tracks (active, inactive, inbound and outbound)
  message SdpAnswer {
    string sdp_answer = 1;
    repeated media_events.shared.MidToTrackId midToTrackId = 2;
  }

  // Informs that the track denoted by `trackId` has changed their voice actiivty
  // For this notification to work, the server must be configured to use VAD extension
  // and the sender must support it.
  message VadNotification {
    enum Status {
      SILENCE = 0;
      SPEECH = 1;
    }

    string track_id = 1;
    Status status = 2;
  }

  oneof content {
    EndpointUpdated endpoint_updated = 1;
    TrackUpdated track_updated = 2;
    TracksAdded tracks_added = 3;
    TracksRemoved tracks_removed = 4;
    EndpointAdded endpoint_added = 5;
    EndpointRemoved endpoint_removed = 6;
    Connected connected = 7;
    Error error = 8;
    OfferData offer_data = 9;
    media_events.shared.Candidate candidate = 10;
    SdpAnswer sdp_answer = 11;
    VadNotification vad_notification = 12;
  }
}
